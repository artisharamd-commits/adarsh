<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NEXUS | Neural Interface</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@300;400;500;600;700&family=JetBrains+Mono&display=swap');
        
        :root {
            --bg: #030303;
            --surface: #0a0a0f;
            --accent: #0070f3;
            --accent-glow: rgba(0, 112, 243, 0.3);
            --text: #ffffff;
            --text-dim: #888888;
            --border: #1a1a24;
        }

        body { 
            font-family: 'Plus Jakarta Sans', sans-serif; 
            background: var(--bg);
            color: var(--text);
            height: 100vh;
            margin: 0;
            overflow: hidden;
        }

        .page-view {
            position: absolute;
            inset: 0;
            transition: all 0.6s cubic-bezier(0.4, 0, 0.2, 1);
            display: flex;
            flex-direction: column;
        }

        .view-hidden {
            opacity: 0;
            pointer-events: none;
            transform: scale(1.05);
            filter: blur(10px);
        }

        .glass-header {
            background: rgba(10, 10, 15, 0.8);
            backdrop-filter: blur(20px);
            border-bottom: 1px solid var(--border);
        }

        .nexus-face {
            width: 140px;
            height: 140px;
            border: 2px solid var(--accent);
            border-radius: 24px;
            position: relative;
            background: rgba(0, 112, 243, 0.05);
            box-shadow: 0 0 40px var(--accent-glow);
        }

        .eye-sq {
            width: 14px;
            height: 14px;
            background: var(--text);
            position: absolute;
            top: 35%;
            border-radius: 3px;
            box-shadow: 0 0 15px var(--accent);
        }
        .eye-left { left: 25%; }
        .eye-right { right: 25%; }
        .eye-blink { animation: blink-sq 4s infinite; }

        @keyframes blink-sq {
            0%, 90%, 100% { transform: scaleY(1); }
            95% { transform: scaleY(0.1); }
        }

        .mouth-sq {
            position: absolute;
            bottom: 25%;
            left: 25%;
            right: 25%;
            height: 4px;
            background: var(--accent);
            border-radius: 4px;
            transition: all 0.3s ease;
        }

        .speaking .mouth-sq {
            animation: talking 0.2s infinite alternate;
        }

        @keyframes talking {
            from { height: 4px; transform: scaleX(1); }
            to { height: 20px; transform: scaleX(0.8); }
        }

        .message-bubble {
            max-width: 80%;
            padding: 1rem 1.5rem;
            border-radius: 20px;
            font-size: 0.95rem;
            line-height: 1.6;
            animation: slideUp 0.4s ease-out;
        }

        @keyframes slideUp {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .loader-dots span {
            width: 6px;
            height: 6px;
            background: var(--accent);
            border-radius: 50%;
            display: inline-block;
            animation: bounce 1.4s infinite ease-in-out both;
        }
        .loader-dots span:nth-child(1) { animation-delay: -0.32s; }
        .loader-dots span:nth-child(2) { animation-delay: -0.16s; }

        @keyframes bounce {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1.0); }
        }

        .scrollbar-hide::-webkit-scrollbar { display: none; }
    </style>
</head>
<body>

    <!-- CHAT PAGE -->
    <div id="page-chat" class="page-view">
        <header class="glass-header px-8 py-4 flex justify-between items-center z-50">
            <div class="flex items-center gap-3">
                <div class="w-8 h-8 rounded-lg bg-blue-600 flex items-center justify-center shadow-lg">
                    <i class="fas fa-microchip text-white text-xs"></i>
                </div>
                <h1 class="font-bold tracking-tight text-sm uppercase">Nexus <span class="text-blue-500">Ultra</span></h1>
            </div>
            <button onclick="switchView('voice')" class="flex items-center gap-2 px-4 py-2 bg-white/5 border border-white/10 rounded-xl text-[10px] font-bold hover:bg-blue-600 transition-all group">
                <i class="fas fa-microphone-alt group-hover:animate-pulse"></i> VOICE SYNC
            </button>
        </header>

        <main class="flex-1 overflow-y-auto p-6 space-y-6 scrollbar-hide" id="chat-scroller">
            <div class="flex flex-col items-start">
                <div class="message-bubble bg-white/5 border border-white/10 text-gray-300 rounded-tl-none">
                    Nexus systems active. Type a message or use Voice Sync for a verbal conversation.
                </div>
            </div>
        </main>

        <footer class="p-6">
            <div class="max-w-4xl mx-auto relative">
                <div id="img-preview-container" class="hidden absolute bottom-full left-0 mb-4 p-2 bg-surface border border-border rounded-2xl shadow-2xl">
                    <img id="img-preview" src="" class="h-24 rounded-lg">
                    <button onclick="clearImage()" class="absolute -top-2 -right-2 bg-red-500 w-5 h-5 rounded-full text-[10px] flex items-center justify-center">âœ•</button>
                </div>
                <form onsubmit="handleChat(event)" class="bg-white/5 border border-white/10 rounded-2xl p-2 flex items-center gap-2 backdrop-blur-xl focus-within:border-blue-500/50 transition-all">
                    <label class="p-3 text-gray-400 hover:text-white cursor-pointer transition-colors">
                        <i class="fas fa-image"></i>
                        <input type="file" id="file-input" accept="image/*" class="hidden" onchange="previewImage(this)">
                    </label>
                    <input type="text" id="user-input" autocomplete="off" placeholder="Message Nexus or 'Draw a...'" class="flex-1 bg-transparent border-none outline-none text-sm px-2">
                    <button type="submit" id="send-btn" class="w-12 h-12 bg-blue-600 rounded-xl hover:bg-blue-500 transition-colors shadow-lg">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </form>
            </div>
        </footer>
    </div>

    <!-- VOICE PAGE -->
    <div id="page-voice" class="page-view view-hidden bg-[#000]">
        <div class="flex-1 flex flex-col items-center justify-center relative">
            <div class="absolute top-10 left-10">
                 <button onclick="exitVoiceMode()" class="px-6 py-2 bg-white/5 border border-white/10 rounded-full text-[10px] font-bold tracking-widest hover:bg-red-500 transition-all">
                    EXIT VOICE
                 </button>
            </div>

            <div class="nexus-face" id="nexus-voice-face">
                <div class="eye-sq eye-left eye-blink"></div>
                <div class="eye-sq eye-right eye-blink"></div>
                <div class="mouth-sq"></div>
            </div>

            <div class="mt-12 text-center">
                <p id="voice-status" class="text-blue-500 text-[10px] font-bold tracking-[0.5em] uppercase opacity-50 mb-4">Awaiting Signal</p>
                <div id="voice-transcript" class="text-xl font-medium max-w-md px-6 leading-relaxed italic text-gray-400"></div>
                <div id="voice-reply-text" class="mt-4 text-sm text-blue-400 font-medium max-w-lg px-8"></div>
            </div>

            <div class="absolute bottom-20 flex gap-4">
                <div class="w-1 h-1 bg-blue-500 rounded-full animate-ping"></div>
                <div class="w-1 h-1 bg-blue-500 rounded-full animate-ping [animation-delay:0.2s]"></div>
                <div class="w-1 h-1 bg-blue-500 rounded-full animate-ping [animation-delay:0.4s]"></div>
            </div>
        </div>
    </div>

    <script>
        const apiKey = "AIzaSyCe3IiOhQwc6h-zJhgu6tiui_krppWSYzE";
        const TEXT_MODEL = "gemini-2.5-flash-preview-09-2025";
        const TTS_MODEL = "gemini-2.5-flash-preview-tts";
        const IMAGE_MODEL = "imagen-4.0-generate-001";

        let currentImageBase64 = null;
        let isProcessing = false;
        let isVoiceActive = false;
        let speechRecognition = null;

        function switchView(view) {
            const chatPage = document.getElementById('page-chat');
            const voicePage = document.getElementById('page-voice');

            if(view === 'voice') {
                isVoiceActive = true;
                chatPage.classList.add('view-hidden');
                voicePage.classList.remove('view-hidden');
                startVoiceRecognition();
            } else {
                isVoiceActive = false;
                chatPage.classList.remove('view-hidden');
                voicePage.classList.add('view-hidden');
                if(speechRecognition) speechRecognition.stop();
            }
        }

        function exitVoiceMode() {
            switchView('chat');
        }

        function setProcessing(state) {
            isProcessing = state;
            const input = document.getElementById('user-input');
            const btn = document.getElementById('send-btn');
            if(input) input.disabled = state;
            if(btn) btn.disabled = state;
            if(input) input.placeholder = state ? "Nexus is thinking..." : "Message Nexus or 'Draw a...'";
        }

        function addMessage(text, role, isImage = false, isLoading = false) {
            const scroller = document.getElementById('chat-scroller');
            const wrap = document.createElement('div');
            wrap.className = `flex flex-col ${role === 'user' ? 'items-end' : 'items-start'} mb-4`;
            
            let content = '';
            if(isLoading) {
                content = `<div class="message-bubble bg-white/5 loader-dots"><span></span> <span></span> <span></span></div>`;
            } else if(isImage) {
                content = `<img src="${text}" class="max-w-xs md:max-w-md rounded-2xl border border-white/10 shadow-2xl">`;
            } else {
                content = `<div class="message-bubble ${role === 'user' ? 'bg-blue-600 text-white rounded-tr-none' : 'bg-white/5 border border-white/10 text-gray-300 rounded-tl-none shadow-lg'}">${text}</div>`;
            }

            wrap.innerHTML = content;
            scroller.appendChild(wrap);
            scroller.scrollTop = scroller.scrollHeight;
            return wrap;
        }

        function previewImage(input) {
            const file = input.files[0];
            if(!file) return;
            const reader = new FileReader();
            reader.onload = (e) => {
                currentImageBase64 = e.target.result.split(',')[1];
                document.getElementById('img-preview').src = e.target.result;
                document.getElementById('img-preview-container').classList.remove('hidden');
            };
            reader.readAsDataURL(file);
        }

        function clearImage() {
            currentImageBase64 = null;
            document.getElementById('img-preview-container').classList.add('hidden');
            document.getElementById('file-input').value = '';
        }

        // Main Chat Handler
        async function handleChat(e, voiceQuery = null) {
            if(e) e.preventDefault();
            if(isProcessing) return;

            const input = document.getElementById('user-input');
            const query = voiceQuery || input.value.trim();
            if(!query && !currentImageBase64) return;

            // Update UI
            if(!voiceQuery) addMessage(query || "Analyzing image...", "user");
            input.value = '';
            setProcessing(true);

            // Image Generation Logic
            const imgTriggers = ["draw", "create image", "generate image", "show image", "make an image"];
            if(imgTriggers.some(t => query.toLowerCase().includes(t))) {
                await generateImage(query, !!voiceQuery);
                setProcessing(false);
                return;
            }

            let chatLoading;
            if(!voiceQuery) chatLoading = addMessage("", "ai", false, true);

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${TEXT_MODEL}:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ 
                            role: 'user', 
                            parts: [
                                { text: query },
                                ...(currentImageBase64 ? [{ inlineData: { mimeType: "image/png", data: currentImageBase64 } }] : [])
                            ] 
                        }],
                        systemInstruction: { parts: [{ text: "You are Nexus, a simple-speaking AI assistant developed by Adarsh Sir. Use simple English." }] }
                    })
                });

                const data = await response.json();
                const reply = data.candidates?.[0]?.content?.parts?.[0]?.text || "Communication error.";
                
                if(voiceQuery) {
                    // In Voice Mode: Update Voice Screen and Speak
                    document.getElementById('voice-reply-text').innerText = reply;
                    await speakText(reply);
                    // Automatically restart listening after speaking
                    startVoiceRecognition();
                } else {
                    // In Chat Mode: Add text bubble only (NO VOICE)
                    chatLoading.remove();
                    addMessage(reply, "ai");
                }
                clearImage();

            } catch(err) {
                if(chatLoading) chatLoading.innerText = "Connection lost.";
            } finally {
                setProcessing(false);
            }
        }

        async function generateImage(prompt, isVoice) {
            let loading;
            if(!isVoice) loading = addMessage("", "ai", false, true);
            else document.getElementById('voice-status').innerText = "Generating Art...";

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${IMAGE_MODEL}:predict?key=${apiKey}`, {
                    method: 'POST',
                    body: JSON.stringify({ instances: { prompt }, parameters: { sampleCount: 1 } })
                });
                const result = await response.json();
                const url = `data:image/png;base64,${result.predictions[0].bytesBase64Encoded}`;
                
                if(!isVoice) {
                    loading.remove();
                    addMessage(url, "ai", true);
                } else {
                    // Switch back to chat to show the image
                    switchView('chat');
                    addMessage(url, "ai", true);
                }
            } catch(e) {
                if(loading) loading.innerText = "Art generation failed.";
            }
        }

        function startVoiceRecognition() {
            const Speech = window.SpeechRecognition || window.webkitSpeechRecognition;
            if(!Speech) return;
            
            speechRecognition = new Speech();
            speechRecognition.onstart = () => {
                document.getElementById('voice-status').innerText = "Listening...";
                document.getElementById('voice-transcript').innerText = "";
            };
            speechRecognition.onresult = (e) => {
                const text = e.results[0][0].transcript;
                document.getElementById('voice-transcript').innerText = `"${text}"`;
                handleChat(null, text);
            };
            speechRecognition.onerror = () => {
                if(isVoiceActive) document.getElementById('voice-status').innerText = "Signal Lost. Try again.";
            };
            speechRecognition.start();
        }

        async function speakText(text) {
            document.getElementById('voice-status').innerText = "Nexus Speaking...";
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${TTS_MODEL}:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: text.substring(0, 300) }] }],
                        generationConfig: { 
                            responseModalities: ["AUDIO"],
                            speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Puck" } } }
                        }
                    })
                });
                const data = await response.json();
                const audioBase64 = data.candidates?.[0]?.content?.parts?.find(p => p.inlineData)?.inlineData?.data;
                if(audioBase64) await playAudio(audioBase64);
            } catch(e) {
                console.error("Speech Error", e);
            }
        }

        function playAudio(base64) {
            return new Promise((resolve) => {
                const bin = atob(base64);
                const bytes = new Uint8Array(bin.length);
                for (let i = 0; i < bin.length; i++) bytes[i] = bin.charCodeAt(i);
                
                const header = new ArrayBuffer(44);
                const view = new DataView(header);
                const str = (off, s) => { for(let i=0; i<s.length; i++) view.setUint8(off+i, s.charCodeAt(i)); };
                str(0, 'RIFF'); view.setUint32(4, 36 + bytes.length, true); str(8, 'WAVE'); str(12, 'fmt ');
                view.setUint32(16, 16, true); view.setUint16(20, 1, true); view.setUint16(22, 1, true);
                view.setUint32(24, 24000, true); view.setUint32(28, 48000, true);
                view.setUint16(32, 2, true); view.setUint16(34, 16, true); str(36, 'data'); view.setUint32(40, bytes.length, true);

                const blob = new Blob([header, bytes], { type: 'audio/wav' });
                const audio = new Audio(URL.createObjectURL(blob));
                document.getElementById('nexus-voice-face').classList.add('speaking');
                audio.onended = () => {
                    document.getElementById('nexus-voice-face').classList.remove('speaking');
                    resolve();
                };
                audio.play().catch(resolve);
            });
        }
    </script>
</body>
</html>